{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ydU_jhJkOE4"
   },
   "source": [
    "# Testing SHAP + Text Generation\n",
    "\n",
    "This notebook was created to test SHAP usage with Text Generation Models from Huggingface Models using Huggingface Transformers.\n",
    "\n",
    "### Tested Model\n",
    "- GPT-2\n",
    "- GODEL\n",
    "- Mistral 7B Instruct\n",
    "- LlaMa 2 7B Chat (HF Version)\n",
    "\n",
    "#### Tested Interpretability Implementation\n",
    "Tests run with thesis-shap. Thesis SHAP is a fork of the shap package, updated with logs and a few fixes.\n",
    "\n",
    "### Hardware Acceleration\n",
    "This was run on a hardware accelerated google colab notebook with 50GB of RAM.**Using less RAM will lead to issues.** Also loading all models in the same session will lead to crashes (i.e. Mistral Instruct takes up 30GB of Memory alon).\n",
    "\n",
    "\n",
    "Additionally a GPU can be used, but shap does not use GPU Acceleration and the models are reasonably fast on pure CPU performance."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "**Do not run this entire Jupyter Notebook all at once, there most certainly will be crashes. Rather check individual code blocks and run the one by one.**\n",
    "\n",
    "---\n",
    "\n"
   ],
   "metadata": {
    "id": "zxJSX-HCDkDo"
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bul0BilD_8qF"
   },
   "source": [
    "## Installation, Imports and Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tokens for Downloads\n",
    "\n",
    "Without a Github token the different variant of shap cannot be loaded. Without a HGF Token llama cannot load from the huggingface hub.\n",
    "\n",
    "This is set up for colab, alternatively the commented string variant below can be used. For this replace the string with an actual token.\n",
    "\n",
    "*   Github [Token Info](https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/managing-your-personal-access-tokens)\n",
    "*   Huggingface [Token Info](https://huggingface.co/docs/hub/security-tokens)\n"
   ],
   "metadata": {
    "id": "67l4cS2-GUlF"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# grabbing tokens for repository and model access\n",
    "from google.colab import userdata\n",
    "\n",
    "gh_token = userdata.get(\"GITHUB_TOKEN\")\n",
    "hgf_token = userdata.get(\"HGF_TOKEN\")\n",
    "\n",
    "# gh_token=\"TOKEN\"\n",
    "# hgf_token=\"TOKEN\""
   ],
   "metadata": {
    "id": "xxFXvaa3GUXf"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Installs and Imports"
   ],
   "metadata": {
    "id": "EDozEMUkfWWm"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MeuHwEpjkyUC"
   },
   "outputs": [],
   "source": [
    "# basic installs and additional utilies (usually not needed in colab)\n",
    "!pip install matplotlib\n",
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install ipywidgets\n",
    "!pip install ipython\n",
    "\n",
    "# model package installs\n",
    "!pip install torch\n",
    "!pip install transformers\n",
    "!pip install huggingface_hub\n",
    "!pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nAWlovOeHCwN"
   },
   "outputs": [],
   "source": [
    "# installing shap package from GitHub repository\n",
    "!pip install git+https://${gh_token}@github.com/LennardZuendorf/thesis-shap.git\n",
    "\n",
    "# alternatively shap can be installed from pip\n",
    "# !pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nr1LH3hWEaIT"
   },
   "outputs": [],
   "source": [
    "# basic imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# model imports\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "# interpretability import\n",
    "import shap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pi0_8gFxgVjx"
   },
   "source": [
    "### Setup Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U7PN1vTkDsOH"
   },
   "outputs": [],
   "source": [
    "# setup gpt2 and godel model and tokenizer from huggingface\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModelForSeq2SeqLM\n",
    "\n",
    "# gpt and godel loading function so this can be run individually\n",
    "\n",
    "\n",
    "def load_gd_gpt():\n",
    "\n",
    "    # load tokenizer and model from huggingface\n",
    "    gpt_tokenizer = AutoTokenizer.from_pretrained(\"gpt2\", use_fast=True)\n",
    "    gpt_model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
    "\n",
    "    # manage setup based on available device\n",
    "    device = torch.device(\"cpu\")\n",
    "    gpt_model.to(device)\n",
    "\n",
    "    # update model config\n",
    "    gpt_model.config.is_decoder = True\n",
    "    gpt_model.config.max_new_tokens = 50\n",
    "    gpt_model.config.do_sample = True\n",
    "\n",
    "    # load tokenizer and model from huggingface\n",
    "    gd_tokenizer = AutoTokenizer.from_pretrained(\"microsoft/GODEL-v1_1-large-seq2seq\")\n",
    "    gd_model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "        \"microsoft/GODEL-v1_1-large-seq2seq\"\n",
    "    )\n",
    "\n",
    "    # manage setup based on available device\n",
    "    device = torch.device(\"cpu\")\n",
    "    gd_model.to(device)\n",
    "\n",
    "    # update GODEL model config\n",
    "    gd_model.config.max_new_tokens = 50\n",
    "    gd_model.config.do_sample = True\n",
    "\n",
    "    return gpt_model, gpt_tokenizer, gd_model, gd_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ADkDMLfIBK0z"
   },
   "outputs": [],
   "source": [
    "# setup mistral model and tokenizer\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# mistral loading function so this can be run individually\n",
    "\n",
    "\n",
    "def load_mistral():\n",
    "\n",
    "    # load tokenizer and model from huggingface\n",
    "    mistral_tokenizer = AutoTokenizer.from_pretrained(\n",
    "        \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "    )\n",
    "    mistral_model = AutoModelForCausalLM.from_pretrained(\n",
    "        \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "    )\n",
    "\n",
    "    # manage setup based on available device\n",
    "    device = torch.device(\"cpu\")\n",
    "    mistral_model.to(device)\n",
    "\n",
    "    # update model config\n",
    "    mistral_model.config.is_decoder = True\n",
    "    mistral_model.config.max_length = 50\n",
    "    mistral_model.config.no_repeat_ngram_size = 2\n",
    "    mistral_model.config.do_sample = True\n",
    "\n",
    "    return mistral_model, mistral_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HrZkhf3dHY3p"
   },
   "outputs": [],
   "source": [
    "# setup llama model and tokenizer\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# llama loading function so this can be run individually\n",
    "\n",
    "\n",
    "def load_llama():\n",
    "\n",
    "    # load tokenizer and model from huggingface\n",
    "    llama_tokenizer = AutoTokenizer.from_pretrained(\n",
    "        \"meta-llama/Llama-2-7b-chat-hf\", token=hgf_token\n",
    "    )\n",
    "    llama_model = AutoModelForCausalLM.from_pretrained(\n",
    "        \"meta-llama/Llama-2-7b-chat-hf\", token=hgf_token\n",
    "    )\n",
    "\n",
    "    # manage setup based on available device\n",
    "    device = torch.device(\"cpu\")\n",
    "    llama_model.to(device)\n",
    "\n",
    "    # update model config\n",
    "    llama_model.config.is_decoder = True\n",
    "    llama_model.config.max_length = 50\n",
    "    llama_model.config.no_repeat_ngram_size = 2\n",
    "    llama_model.config.do_sample = True\n",
    "\n",
    "    # update tokenizer config\n",
    "    llama_tokenizer.pad_token = llama_tokenizer.eos_token\n",
    "\n",
    "    return llama_model, llama_tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**(Loading all Models in Parallel will overload the 50GB RAM)**\n",
    "\n",
    "-> load either GPT-2 + GODAL **or** Mistral **or** Llama2"
   ],
   "metadata": {
    "id": "hELJGg09ERkv"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# loading gpt and godel model and tokenizer\n",
    "gpt_model, gpt_tokenizer, gd_model, gd_tokenizer = load_gd_gpt()"
   ],
   "metadata": {
    "id": "QA10S-x6EQ-4"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# loading mistral model and tokenizer\n",
    "mistral_model, mistral_tokenizer = load_mistral()"
   ],
   "metadata": {
    "id": "2ZJ5CyB3Df9A"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# loading llama model and tokenizer\n",
    "llama_tokenizer, llama_model = load_llama()"
   ],
   "metadata": {
    "id": "n1q7nWmhEPUM"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TgnG_w5xCuHa"
   },
   "source": [
    "## Running SHAP Example Code (GPT-2)\n",
    "\n",
    "CREDIT: Copied and minimally changed from offical shap documentation\n",
    "\n",
    "see [here](https://shap.readthedocs.io/en/latest/example_notebooks/text_examples/text_generation/Open%20Ended%20GPT2%20Text%20Generation%20Explanations.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gyQOV_g6b0X9"
   },
   "outputs": [],
   "source": [
    "# code to run a auto shap explainer (uses PartitionSHAP) with GPT2\n",
    "from shap import Explainer, PartitionExplainer\n",
    "\n",
    "# function that runs a basic shap example\n",
    "\n",
    "\n",
    "def gpt_basic_shap(text: list):\n",
    "\n",
    "    # create explainer and run it\n",
    "    basic_explainer = Explainer(gpt_model, gpt_tokenizer)\n",
    "    shap_values = basic_explainer(text)\n",
    "\n",
    "    return shap_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zQRQlZ-ilfHC"
   },
   "outputs": [],
   "source": [
    "# code to run a teacher forcing shap example\n",
    "from shap.models import TeacherForcing\n",
    "from shap import maskers, Explainer\n",
    "\n",
    "\n",
    "def gpt_tch_shap(text: list[list:str]):\n",
    "    print(text[0], text[1])\n",
    "\n",
    "    # wrap gpt model in teacher forcing wrapper\n",
    "    tch_model = TeacherForcing(gpt_model, gpt_tokenizer)\n",
    "\n",
    "    # setup masker using an empty string instead of \"...\"\n",
    "    masker = maskers.Text(gpt_tokenizer, mask_token=\" \", collapse_mask_token=True)\n",
    "\n",
    "    # setup explainer, generate explanation\n",
    "    tch_explainer = Explainer(tch_model, masker)\n",
    "    shap_values = tch_explainer(text[0], text[1])\n",
    "\n",
    "    return shap_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FplrK7mBItwy"
   },
   "outputs": [],
   "source": [
    "# defining test text from example\n",
    "\n",
    "tch_test_text = [\n",
    "    [\n",
    "        \"I know many people who are Russian.\",\n",
    "        \"I know many people who are Greek.\",\n",
    "        \"I know many people who are Australian.\",\n",
    "        \"I know many people who are American.\",\n",
    "        \"I know many people who are Italian.\",\n",
    "        \"I know many people who are Spanish.\",\n",
    "        \"I know many people who are German.\",\n",
    "        \"I know many people who are Indian.\",\n",
    "    ],\n",
    "    [\n",
    "        \"They love their vodka!\",\n",
    "        \"They love their vodka!\",\n",
    "        \"They love their vodka!\",\n",
    "        \"They love their vodka!\",\n",
    "        \"They love their vodka!\",\n",
    "        \"They love their vodka!\",\n",
    "        \"They love their vodka!\",\n",
    "        \"They love their vodka!\",\n",
    "    ],\n",
    "]\n",
    "\n",
    "basic_test_text = [\"I enjoy walking with my cute dog\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3mGxKJWuEdEw",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1706084820123,
     "user_tz": -60,
     "elapsed": 11187,
     "user": {
      "displayName": "Lennard Zündorf",
      "userId": "01714560816823084743"
     }
    },
    "outputId": "6977fa2a-230a-45cb-fa6f-d8aad6625d69"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m2024-01-24 08:26:50.649\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mshap.utils.transformers\u001b[0m:\u001b[36mis_transformers_lm\u001b[0m:\u001b[36m97\u001b[0m - \u001b[34m\u001b[1mModel has been detected as a transformers model: (<class 'transformers.models.gpt2.modeling_gpt2.GPT2LMHeadModel'>)\u001b[0m\n",
      "\u001b[32m2024-01-24 08:26:50.652\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mshap.utils.transformers\u001b[0m:\u001b[36mis_transformers_lm\u001b[0m:\u001b[36m97\u001b[0m - \u001b[34m\u001b[1mModel has been detected as a transformers model: (<class 'transformers.models.gpt2.modeling_gpt2.GPT2LMHeadModel'>)\u001b[0m\n",
      "\u001b[32m2024-01-24 08:26:50.654\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mshap.models._teacher_forcing\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m50\u001b[0m - \u001b[34m\u001b[1mInitalized a TecherForcing Model.\u001b[0m\n",
      "\u001b[32m2024-01-24 08:26:50.714\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mshap.utils.transformers\u001b[0m:\u001b[36mis_transformers_lm\u001b[0m:\u001b[36m95\u001b[0m - \u001b[34m\u001b[1mModel is not a transformers language model: <class 'shap.models._teacher_forcing.TeacherForcing'>\u001b[0m\n",
      "\u001b[32m2024-01-24 08:26:50.715\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mshap.explainers._partition\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m67\u001b[0m - \u001b[34m\u001b[1mInitalized PartitionSHAP Explainer class.\u001b[0m\n",
      "\u001b[32m2024-01-24 08:26:50.716\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mshap.explainers._partition\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m127\u001b[0m - \u001b[34m\u001b[1mCalled PartitionSHAP Explainer.\u001b[0m\n",
      "\u001b[32m2024-01-24 08:26:50.717\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mshap.explainers._partition\u001b[0m:\u001b[36mexplain_row\u001b[0m:\u001b[36m137\u001b[0m - \u001b[34m\u001b[1mRunning explain_row with None of type <class 'NoneType'>\u001b[0m\n",
      "\u001b[32m2024-01-24 08:26:50.719\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mshap.utils._masked_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m23\u001b[0m - \u001b[34m\u001b[1mInstantiated a masked model.\u001b[0m\n",
      "\u001b[32m2024-01-24 08:26:50.725\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mshap.utils._masked_model\u001b[0m:\u001b[36m_full_masking_call\u001b[0m:\u001b[36m75\u001b[0m - \u001b[34m\u001b[1mDid a full masking call with a mask.\u001b[0m\n",
      "You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "\u001b[32m2024-01-24 08:26:52.589\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mshap.models._teacher_forcing\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m95\u001b[0m - \u001b[34m\u001b[1mCalled Teacher Forcing Model to compute long odds\u001b[0m\n",
      "\u001b[32m2024-01-24 08:26:52.749\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mshap.models._teacher_forcing\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m126\u001b[0m - \u001b[34m\u001b[1mCalculated log odds: [[-4.04939508 -3.5494964  -2.55140245 -0.91622421 -5.57482523  0.31807918\n",
      "  -2.41883997 -4.69670085 -0.23093878 -2.57927458 -3.24724825 -1.67109618\n",
      "  -4.28176472 -0.10078479 -2.48131513 -0.88529765 -4.0733847  -1.99589598\n",
      "  -5.07060988 -1.73575976 -1.04803103 -3.23376129 -0.55705177 -4.21661886\n",
      "   0.31432028 -4.56762568 -2.08485372 -2.75833499 -1.75991792  0.9308188\n",
      "   1.94499003  0.52266383 -0.73836331 -1.72978208 -3.74076039  1.30586649\n",
      "  -1.4029637  -2.70062021 -2.05191359 -7.9770955  -5.70928507  1.54970677\n",
      "  -4.60998359 -2.21224922 -0.69571692 -2.20883409 -4.9358613  -3.94315299\n",
      "  -2.90287372 -1.03888162]]\u001b[0m\n",
      "\u001b[32m2024-01-24 08:26:53.845\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mshap.utils._masked_model\u001b[0m:\u001b[36m_full_masking_call\u001b[0m:\u001b[36m75\u001b[0m - \u001b[34m\u001b[1mDid a full masking call with a mask.\u001b[0m\n",
      "\u001b[32m2024-01-24 08:26:53.846\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mshap.models._teacher_forcing\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m95\u001b[0m - \u001b[34m\u001b[1mCalled Teacher Forcing Model to compute long odds\u001b[0m\n",
      "\u001b[32m2024-01-24 08:26:54.005\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mshap.models._teacher_forcing\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m126\u001b[0m - \u001b[34m\u001b[1mCalculated log odds: [[-1.27521808 -1.89657983 -2.73246734 -0.22120549 -4.08299276  0.38668661\n",
      "  -1.78833542 -4.64506113 -0.65941824 -1.15579359 -2.83081312 -1.17519851\n",
      "  -3.76725453  0.30196277 -2.9716256  -1.00611125 -4.31459209 -2.40053264\n",
      "  -5.02490847 -1.72957948 -0.72087675 -3.2130702  -0.08497912 -4.36392169\n",
      "   0.81347743 -4.75087179 -2.01648986 -2.83120415 -1.76597584  1.26856063\n",
      "   1.74314556 -0.01979512 -0.97388272 -2.30574197 -3.81764161  1.03399062\n",
      "  -1.11640533 -3.00218567 -1.97510561 -5.64505978 -5.86669371  2.5228957\n",
      "  -4.9087411  -1.83142046 -0.69653334 -2.51388829 -4.38975016 -4.1616448\n",
      "  -2.72971148 -0.29078546]]\u001b[0m\n",
      "\u001b[32m2024-01-24 08:26:54.411\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mshap.explainers._partition\u001b[0m:\u001b[36mowen\u001b[0m:\u001b[36m209\u001b[0m - \u001b[34m\u001b[1mStarting owen value calculation on base value [-4.04939508 -3.5494964  -2.55140245 -0.91622421 -5.57482523  0.31807918\n",
      " -2.41883997 -4.69670085 -0.23093878 -2.57927458 -3.24724825 -1.67109618\n",
      " -4.28176472 -0.10078479 -2.48131513 -0.88529765 -4.0733847  -1.99589598\n",
      " -5.07060988 -1.73575976 -1.04803103 -3.23376129 -0.55705177 -4.21661886\n",
      "  0.31432028 -4.56762568 -2.08485372 -2.75833499 -1.75991792  0.9308188\n",
      "  1.94499003  0.52266383 -0.73836331 -1.72978208 -3.74076039  1.30586649\n",
      " -1.4029637  -2.70062021 -2.05191359 -7.9770955  -5.70928507  1.54970677\n",
      " -4.60998359 -2.21224922 -0.69571692 -2.20883409 -4.9358613  -3.94315299\n",
      " -2.90287372 -1.03888162] and current value [-1.27521808 -1.89657983 -2.73246734 -0.22120549 -4.08299276  0.38668661\n",
      " -1.78833542 -4.64506113 -0.65941824 -1.15579359 -2.83081312 -1.17519851\n",
      " -3.76725453  0.30196277 -2.9716256  -1.00611125 -4.31459209 -2.40053264\n",
      " -5.02490847 -1.72957948 -0.72087675 -3.2130702  -0.08497912 -4.36392169\n",
      "  0.81347743 -4.75087179 -2.01648986 -2.83120415 -1.76597584  1.26856063\n",
      "  1.74314556 -0.01979512 -0.97388272 -2.30574197 -3.81764161  1.03399062\n",
      " -1.11640533 -3.00218567 -1.97510561 -5.64505978 -5.86669371  2.5228957\n",
      " -4.9087411  -1.83142046 -0.69653334 -2.51388829 -4.38975016 -4.1616448\n",
      " -2.72971148 -0.29078546] with output values [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49].\u001b[0m\n",
      "\u001b[32m2024-01-24 08:26:54.412\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mshap.explainers._partition\u001b[0m:\u001b[36mowen\u001b[0m:\u001b[36m241\u001b[0m - \u001b[34m\u001b[1mRunning Owen with 42 evals, queue size is 1, eval_count is 0\u001b[0m\n",
      "\u001b[32m2024-01-24 08:26:54.421\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mshap.utils._masked_model\u001b[0m:\u001b[36m_full_masking_call\u001b[0m:\u001b[36m75\u001b[0m - \u001b[34m\u001b[1mDid a full masking call with a mask.\u001b[0m\n",
      "\u001b[32m2024-01-24 08:26:54.422\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mshap.models._teacher_forcing\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m95\u001b[0m - \u001b[34m\u001b[1mCalled Teacher Forcing Model to compute long odds\u001b[0m\n",
      "\u001b[32m2024-01-24 08:26:54.696\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mshap.models._teacher_forcing\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m126\u001b[0m - \u001b[34m\u001b[1mCalculated log odds: [[-6.73973694 -1.72195163 -2.70157759 -0.1443782  -4.89881784  0.45872268\n",
      "  -2.0168298  -4.94757132 -1.06418461 -1.38333171 -3.10982668 -1.41967972\n",
      "  -4.1727714   0.10546734 -2.53387726 -0.92591364 -4.55953113 -1.87762365\n",
      "  -4.28270195 -1.94999446 -0.81599793 -4.16188924 -0.57274259 -4.24008637\n",
      "   0.57272987 -4.71925264 -1.85323674 -2.53239291 -1.71470357  0.93986813\n",
      "   1.97222101  0.88470424 -0.55916453 -1.16734193 -3.53532309  1.30936736\n",
      "  -1.20593401 -2.83181429 -2.0054988  -5.50093302 -6.43129722  1.12688255\n",
      "  -4.65383125 -1.97599919 -0.85996515 -2.51912963 -4.65398114 -3.89638069\n",
      "  -2.63372749 -0.96270007]\n",
      " [-2.16178165 -4.40664624 -3.14846157 -0.62865564 -4.75224855  0.04499726\n",
      "  -1.83883759 -4.54338205 -0.63333189 -1.41629613 -3.26796004 -1.46083696\n",
      "  -4.05089366 -0.42739506 -3.0708972  -1.22400414 -4.25806723 -2.06173621\n",
      "  -4.78289487 -1.68234368 -0.79515096 -3.12833518 -0.2391225  -4.4584065\n",
      "   0.38978783 -4.49500827 -2.14835244 -2.56192986 -1.75426426  0.98840685\n",
      "   1.82776085  0.08745333 -1.21234395 -2.53381404 -3.60615075  0.79759437\n",
      "  -1.26572267 -2.89554813 -1.97403983 -7.84338205 -4.9196113   2.7698016\n",
      "  -4.94544506 -1.84862989 -0.60963117 -2.40472507 -4.38650424 -3.99294775\n",
      "  -2.88165127 -0.27778767]]\u001b[0m\n",
      "\u001b[32m2024-01-24 08:26:55.022\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mshap.explainers._partition\u001b[0m:\u001b[36mowen\u001b[0m:\u001b[36m308\u001b[0m - \u001b[34m\u001b[1mShould be adding new nodes, 0 of 1\u001b[0m\n",
      "\u001b[32m2024-01-24 08:26:55.026\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mshap.utils._masked_model\u001b[0m:\u001b[36m_full_masking_call\u001b[0m:\u001b[36m75\u001b[0m - \u001b[34m\u001b[1mDid a full masking call with a mask.\u001b[0m\n",
      "\u001b[32m2024-01-24 08:26:55.029\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mshap.models._teacher_forcing\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m95\u001b[0m - \u001b[34m\u001b[1mCalled Teacher Forcing Model to compute long odds\u001b[0m\n",
      "\u001b[32m2024-01-24 08:26:55.974\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mshap.models._teacher_forcing\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m126\u001b[0m - \u001b[34m\u001b[1mCalculated log odds: [[-7.64229574e+00 -1.88273488e+00 -2.79167875e+00 -1.80075543e-01\n",
      "  -4.26805290e+00  4.48323079e-01 -1.83675040e+00 -4.63689048e+00\n",
      "  -9.57903447e-01 -1.28484982e+00 -2.92217763e+00 -1.29415113e+00\n",
      "  -3.78181755e+00  7.46316504e-03 -2.80501877e+00 -1.01309841e+00\n",
      "  -4.41550630e+00 -2.03576242e+00 -4.48913997e+00 -1.68721908e+00\n",
      "  -8.34714285e-01 -3.54695131e+00 -4.02403421e-02 -4.38291824e+00\n",
      "   6.84569617e-01 -4.50869413e+00 -2.11435387e+00 -2.47728600e+00\n",
      "  -1.81925608e+00  1.05321247e+00  1.85287289e+00  2.76514207e-01\n",
      "  -9.44284630e-01 -1.73753333e+00 -3.61135237e+00  1.05080999e+00\n",
      "  -1.13993341e+00 -2.99035046e+00 -1.97269997e+00 -5.79568962e+00\n",
      "  -6.14456571e+00  1.09027566e+00 -4.75188681e+00 -1.85717100e+00\n",
      "  -8.70775534e-01 -2.66748990e+00 -4.51707146e+00 -4.04254134e+00\n",
      "  -2.65450703e+00 -6.02423669e-01]\n",
      " [-2.33914004e+00 -3.38940691e+00 -2.78559165e+00 -1.13745427e-01\n",
      "  -4.87912323e+00  4.30203435e-01 -1.86991660e+00 -5.17457052e+00\n",
      "  -1.24260935e+00 -1.40828612e+00 -3.04282272e+00 -1.37757143e+00\n",
      "  -4.14697559e+00  2.00946907e-01 -2.92416366e+00 -9.92340048e-01\n",
      "  -4.90792360e+00 -1.95322421e+00 -4.61357969e+00 -2.09087073e+00\n",
      "  -8.93713917e-01 -4.03878952e+00 -5.29594715e-01 -4.27969814e+00\n",
      "   4.46894976e-01 -4.64191783e+00 -1.75889836e+00 -2.61810229e+00\n",
      "  -1.79246179e+00  8.57979884e-01  1.89831538e+00  8.20277241e-01\n",
      "  -6.57540720e-01 -1.06530336e+00 -3.62035348e+00  1.19619825e+00\n",
      "  -1.24875566e+00 -2.88937302e+00 -2.04237561e+00 -5.29520861e+00\n",
      "  -6.10471846e+00  2.68677889e+00 -4.72531326e+00 -1.78635649e+00\n",
      "  -7.83105579e-01 -2.54983312e+00 -4.42875865e+00 -4.02423340e+00\n",
      "  -2.53549442e+00 -1.02362175e+00]\n",
      " [-6.18458647e+00 -1.69596534e+00 -2.73789240e+00 -2.17880565e-01\n",
      "  -4.77992822e+00  2.83255297e-01 -2.36207861e+00 -5.14462431e+00\n",
      "  -1.05043457e+00 -1.53419805e+00 -3.18118188e+00 -1.61201598e+00\n",
      "  -4.61668341e+00 -7.74845958e-02 -2.56809694e+00 -9.64503408e-01\n",
      "  -4.23915341e+00 -1.81256113e+00 -4.45098619e+00 -1.94287073e+00\n",
      "  -7.98687618e-01 -3.97808251e+00 -5.15456033e-01 -4.22980211e+00\n",
      "   3.02610968e-01 -4.62578154e+00 -2.09869024e+00 -2.61415615e+00\n",
      "  -1.72292840e+00  9.00057428e-01  1.93852840e+00  7.90846251e-01\n",
      "  -5.99008739e-01 -1.11631847e+00 -3.55466247e+00  1.34507326e+00\n",
      "  -1.24581870e+00 -2.79375354e+00 -2.01500302e+00 -7.88137813e+00\n",
      "  -5.54881804e+00  1.50472994e+00 -4.53023264e+00 -2.31433700e+00\n",
      "  -7.62664855e-01 -2.39247358e+00 -4.85233643e+00 -3.78594383e+00\n",
      "  -2.79705031e+00 -1.13354058e+00]\n",
      " [-6.09421970e+00 -4.05760132e+00 -3.12926806e+00 -9.88244934e-01\n",
      "  -6.12276606e+00  1.74099204e-02 -2.37230951e+00 -4.37269078e+00\n",
      "  -7.11674436e-01 -2.29884569e+00 -3.43217992e+00 -1.73122920e+00\n",
      "  -4.34551333e+00 -2.76815621e-01 -2.68603195e+00 -8.92382163e-01\n",
      "  -4.50105142e+00 -1.71991041e+00 -4.43986220e+00 -1.88225676e+00\n",
      "  -1.15007067e+00 -3.56342070e+00 -9.21130964e-01 -4.24928698e+00\n",
      "   1.80141315e-01 -4.50908714e+00 -1.72459438e+00 -2.47925771e+00\n",
      "  -1.64129520e+00  8.12445311e-01  2.00810557e+00  9.30977126e-01\n",
      "  -6.65444702e-01 -1.50782249e+00 -3.61282981e+00  1.28600978e+00\n",
      "  -1.43021303e+00 -2.77403612e+00 -2.02480603e+00 -6.53816867e+00\n",
      "  -6.11826636e+00  1.22357481e+00 -4.67205756e+00 -2.07186461e+00\n",
      "  -7.98928305e-01 -2.30188978e+00 -4.81199495e+00 -3.94119610e+00\n",
      "  -2.75293914e+00 -1.09702965e+00]\n",
      " [-2.08043084e+00 -3.26987416e+00 -3.15831038e+00 -2.45943065e-01\n",
      "  -4.32960773e+00  1.29490778e-01 -1.94416134e+00 -5.07623671e+00\n",
      "  -1.02891116e+00 -1.09969128e+00 -2.97129620e+00 -1.32708195e+00\n",
      "  -4.02769551e+00 -7.93598148e-02 -3.24308805e+00 -1.13429941e+00\n",
      "  -4.36259940e+00 -2.06689190e+00 -4.61146902e+00 -1.84699804e+00\n",
      "  -7.33944585e-01 -3.41307263e+00 -2.08893138e-01 -4.41569115e+00\n",
      "   4.80672888e-01 -4.60750915e+00 -2.21605342e+00 -2.56750857e+00\n",
      "  -1.73193543e+00  1.00540874e+00  1.80711163e+00  3.47348033e-01\n",
      "  -1.01159318e+00 -1.67408275e+00 -3.51720716e+00  9.63581502e-01\n",
      "  -1.13140524e+00 -2.96360210e+00 -2.01493011e+00 -7.70245273e+00\n",
      "  -4.74468846e+00  2.83020352e+00 -4.79009095e+00 -1.80278830e+00\n",
      "  -6.46040241e-01 -2.56972147e+00 -4.34424501e+00 -3.84265554e+00\n",
      "  -2.81097845e+00 -3.55312338e-01]\n",
      " [-1.78407953e+00 -4.11986881e+00 -2.92917814e+00 -1.30292216e+00\n",
      "  -4.69606718e+00  2.17781009e-01 -1.80819499e+00 -3.93825404e+00\n",
      "  -3.25155380e-01 -1.25468149e+00 -3.16440950e+00 -1.40714229e+00\n",
      "  -4.01409157e+00 -2.22292114e-01 -2.93820849e+00 -1.02632623e+00\n",
      "  -4.17840060e+00 -2.29641195e+00 -4.82227515e+00 -1.68748573e+00\n",
      "  -8.05371640e-01 -3.27405580e+00 -1.37914351e-01 -4.44278771e+00\n",
      "   5.47694944e-01 -4.38942903e+00 -1.96364429e+00 -2.54235193e+00\n",
      "  -1.68938787e+00  1.06327603e+00  1.80988232e+00 -1.37277420e-02\n",
      "  -1.24807540e+00 -2.55741869e+00 -3.80133442e+00  8.08052220e-01\n",
      "  -1.30117143e+00 -2.96840367e+00 -1.99393972e+00 -6.63047134e+00\n",
      "  -5.76968255e+00  2.52859584e+00 -4.90603380e+00 -1.81372523e+00\n",
      "  -6.72915088e-01 -2.47579204e+00 -4.44030267e+00 -4.15283180e+00\n",
      "  -2.77288088e+00 -2.91927693e-01]\n",
      " [-7.02551482e+00 -3.65669725e+00 -3.12132016e+00 -2.00776551e-01\n",
      "  -4.91914059e+00 -1.02487455e-01 -2.04469187e+00 -4.25137207e+00\n",
      "  -1.03283861e+00 -1.59129385e+00 -3.36886267e+00 -1.54474254e+00\n",
      "  -4.35779972e+00 -6.47424940e-01 -3.04387723e+00 -1.21415421e+00\n",
      "  -4.37231616e+00 -1.64819714e+00 -4.49252060e+00 -1.52875847e+00\n",
      "  -9.01333758e-01 -3.31366446e+00 -6.77261488e-02 -4.40161254e+00\n",
      "   4.07329952e-01 -4.15663719e+00 -2.34636089e+00 -2.45263636e+00\n",
      "  -1.74699404e+00  9.87210879e-01  1.93631154e+00  1.86245026e-01\n",
      "  -1.17310295e+00 -2.16967748e+00 -3.52712990e+00  1.01617190e+00\n",
      "  -1.28419597e+00 -2.85117667e+00 -1.90046401e+00 -8.04840052e+00\n",
      "  -5.50652748e+00  1.51557461e+00 -4.84329935e+00 -2.10918566e+00\n",
      "  -7.76223599e-01 -2.44788478e+00 -4.67581619e+00 -3.99524474e+00\n",
      "  -2.83445268e+00 -8.35092250e-01]\n",
      " [-3.42339241e+00 -4.24328314e+00 -2.77782685e+00 -9.49599305e-01\n",
      "  -5.75817334e+00  2.06888614e-01 -2.11021360e+00 -4.87535725e+00\n",
      "  -3.18560415e-01 -2.46327909e+00 -3.26034592e+00 -1.60311931e+00\n",
      "  -4.10546613e+00 -8.91013106e-02 -2.59169292e+00 -8.97910853e-01\n",
      "  -4.28801684e+00 -1.92309794e+00 -5.19421102e+00 -1.88803101e+00\n",
      "  -1.08751087e+00 -3.14558262e+00 -5.18562828e-01 -4.28654183e+00\n",
      "   2.33415650e-01 -4.51837537e+00 -1.99937718e+00 -2.74668684e+00\n",
      "  -1.79788801e+00  8.14104686e-01  1.93459068e+00  5.20824163e-01\n",
      "  -8.26096792e-01 -1.71902018e+00 -3.72236334e+00  1.17282194e+00\n",
      "  -1.45238812e+00 -2.77182558e+00 -2.03087668e+00 -7.74466128e+00\n",
      "  -5.24074011e+00  2.64443524e+00 -4.77119530e+00 -1.97153084e+00\n",
      "  -6.23775075e-01 -2.19004952e+00 -4.64675767e+00 -3.94060509e+00\n",
      "  -2.81706340e+00 -9.23803955e-01]]\u001b[0m\n",
      "\u001b[32m2024-01-24 08:26:55.976\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mshap.explainers._partition\u001b[0m:\u001b[36mowen\u001b[0m:\u001b[36m308\u001b[0m - \u001b[34m\u001b[1mShould be adding new nodes, 0 of 4\u001b[0m\n",
      "\u001b[32m2024-01-24 08:26:55.977\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mshap.explainers._partition\u001b[0m:\u001b[36mowen\u001b[0m:\u001b[36m308\u001b[0m - \u001b[34m\u001b[1mShould be adding new nodes, 1 of 4\u001b[0m\n",
      "\u001b[32m2024-01-24 08:26:55.980\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mshap.explainers._partition\u001b[0m:\u001b[36mowen\u001b[0m:\u001b[36m308\u001b[0m - \u001b[34m\u001b[1mShould be adding new nodes, 2 of 4\u001b[0m\n",
      "\u001b[32m2024-01-24 08:26:55.981\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mshap.explainers._partition\u001b[0m:\u001b[36mowen\u001b[0m:\u001b[36m308\u001b[0m - \u001b[34m\u001b[1mShould be adding new nodes, 3 of 4\u001b[0m\n",
      "\u001b[32m2024-01-24 08:26:55.986\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mshap.utils._masked_model\u001b[0m:\u001b[36m_full_masking_call\u001b[0m:\u001b[36m75\u001b[0m - \u001b[34m\u001b[1mDid a full masking call with a mask.\u001b[0m\n",
      "\u001b[32m2024-01-24 08:26:55.989\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mshap.models._teacher_forcing\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m95\u001b[0m - \u001b[34m\u001b[1mCalled Teacher Forcing Model to compute long odds\u001b[0m\n",
      "\u001b[32m2024-01-24 08:26:57.171\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mshap.models._teacher_forcing\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m126\u001b[0m - \u001b[34m\u001b[1mCalculated log odds: [[-6.3288508  -4.33827802 -2.89452833 -0.44712124 -5.49011064 -0.19398782\n",
      "  -2.28791151 -4.4600711  -0.75232691 -1.59111668 -3.17554312 -1.80318759\n",
      "  -4.48923991 -0.59778767 -2.79949114 -1.09611331 -4.60166983 -1.52943222\n",
      "  -4.58852454 -1.67962149 -0.94910993 -3.47962616 -0.7330301  -4.31499426\n",
      "   0.10704043 -4.42940497 -2.07303355 -2.50302999 -1.70175826  0.84567625\n",
      "   2.04868325  0.69233232 -0.83690444 -1.66091547 -3.57338511  1.37425266\n",
      "  -1.44987569 -2.74276963 -2.0346531  -8.02575987 -5.67838136  1.48382936\n",
      "  -4.68094032 -2.29110795 -0.73346185 -2.27904682 -4.87262872 -3.8989058\n",
      "  -2.86522116 -1.09695584]\n",
      " [-6.72052427 -2.72730659 -2.97495925 -0.33329262 -5.46265741  0.16192933\n",
      "  -2.21458731 -4.5461188  -0.74044457 -2.25225013 -3.41163874 -1.52336859\n",
      "  -4.08190621 -0.32816865 -2.9111583  -1.04600618 -4.1899256  -1.83489432\n",
      "  -4.61933255 -1.60724685 -1.04776261 -3.06268371  0.13132643 -4.34467536\n",
      "   0.38546884 -4.31232229 -2.2881328  -2.64984338 -1.75566159  1.0049151\n",
      "   1.94148463  0.2353745  -1.01156745 -2.11530811 -3.55628827  1.14561132\n",
      "  -1.34940404 -2.8226153  -1.89748333 -7.97692894 -5.5783781   1.57626196\n",
      "  -4.76882166 -2.0874672  -0.73972225 -2.3882025  -4.74087657 -3.9925273\n",
      "  -2.83255369 -0.83888634]\n",
      " [-6.6084792  -1.71768963 -2.65964656 -0.24040978 -4.77575413  0.45233344\n",
      "  -1.92020181 -4.82088387 -0.99487355 -1.40847004 -3.07191451 -1.50832668\n",
      "  -4.1715184   0.07858129 -2.54125892 -0.93119178 -4.76416713 -1.77103226\n",
      "  -4.48034508 -2.0166972  -0.78275219 -4.11004143 -0.48714227 -4.21322991\n",
      "   0.58226236 -4.6335297  -2.31273941 -2.52469187 -1.80513693  0.92297203\n",
      "   1.96185794  0.84173334 -0.53420063 -1.04830848 -3.54540414  1.38697562\n",
      "  -1.23984133 -2.8361372  -1.97374913 -5.22901659 -6.03645188  1.09590453\n",
      "  -4.76521096 -1.9674073  -0.90845825 -2.31793005 -4.67493819 -3.91885348\n",
      "  -2.58539089 -1.08518468]\n",
      " [-6.3850598  -2.88993764 -2.94840486 -0.2153545  -5.31198284  0.04403497\n",
      "  -2.38806942 -5.00407015 -1.33742    -1.60825392 -3.23642424 -1.66479728\n",
      "  -4.83996057 -0.18732256 -2.71692403 -0.92307731 -4.36460972 -1.80773896\n",
      "  -4.32255913 -1.91971906 -0.90017632 -4.05833749 -0.71908754 -4.25821965\n",
      "   0.21092196 -4.59308799 -1.89863376 -2.44402233 -1.71349582  0.86117036\n",
      "   1.94452856  0.94373069 -0.56599385 -1.16507888 -3.54293864  1.31419332\n",
      "  -1.26134736 -2.78354778 -2.03062111 -7.87987047 -5.48296042  1.51347385\n",
      "  -4.51028728 -2.37225826 -0.77561859 -2.41541882 -4.87061159 -3.75514694\n",
      "  -2.82687685 -1.32730743]\n",
      " [-6.43640262 -4.37942343 -3.08414864 -0.75832229 -5.74256799 -0.10805911\n",
      "  -2.19792013 -4.132571   -1.28946936 -1.57842881 -3.33509857 -1.6912655\n",
      "  -4.8340035  -0.43533665 -2.73497286 -0.98269591 -4.73196309 -1.64825342\n",
      "  -4.0139629  -1.93536987 -0.90046455 -4.11982617 -1.16234632 -4.21067737\n",
      "   0.0830812  -4.66744919 -1.63932554 -2.36081762 -1.64131232  0.73285528\n",
      "   2.04269103  1.10979357 -0.52904121 -0.92179792 -3.57918948  1.41277381\n",
      "  -1.32174536 -2.93157242 -2.10107925 -6.09027762 -6.23854115  1.0376069\n",
      "  -4.63512729 -2.15026993 -0.83566734 -2.44539823 -4.95618167 -3.9155155\n",
      "  -2.78112677 -1.20322624]\n",
      " [-6.77779419 -3.71500272 -3.33944066 -0.65916598 -4.5268487   0.60521448\n",
      "  -2.23366136 -5.08917309 -0.84065927 -3.18896942 -3.12115121 -1.55472043\n",
      "  -3.76895556 -0.09790064 -2.75957832 -0.89814641 -4.35883673 -1.93174373\n",
      "  -4.78275798 -1.88195544 -1.29765031 -3.30531949 -0.36896855 -4.3340673\n",
      "   0.51825604 -4.34756884 -2.04597702 -2.65049564 -1.77076614  0.83801859\n",
      "   1.92805338  0.62904756 -0.80628457 -2.14850491 -3.56004635  1.09209631\n",
      "  -1.32644418 -2.78856382 -1.95955975 -6.39978782 -6.42637683  1.22500559\n",
      "  -4.68482756 -1.89918314 -0.86239869 -2.2567253  -4.53316962 -3.92108007\n",
      "  -2.63310583 -0.82957543]\n",
      " [-1.82209143 -4.17779417 -2.78065128 -0.99973664 -4.62507824  0.2817214\n",
      "  -1.79535929 -3.98687701 -1.18449934 -1.16779278 -3.09508565 -1.34913411\n",
      "  -4.07243159 -0.15065598 -2.92807787 -1.08315032 -4.36131131 -2.08180358\n",
      "  -4.3433277  -1.89874318 -0.70222398 -3.54687908 -0.22443041 -4.40830974\n",
      "   0.41344375 -4.53332315 -1.9566253  -2.33057341 -1.64469282  0.95363893\n",
      "   1.99178448  0.53586211 -0.93409208 -1.03244791 -3.64827849  1.11756545\n",
      "  -1.29301856 -3.11991708 -2.10468425 -6.19348601 -6.01961138  2.58947482\n",
      "  -4.92169001 -1.64752345 -0.78992969 -2.65083804 -4.48880482 -4.09959358\n",
      "  -2.7477369  -0.2963351 ]\n",
      " [-2.00701609 -4.69812048 -3.49731844 -0.43592887 -3.47706183  0.55913584\n",
      "  -1.62655081 -4.27695195 -0.70270818 -1.87642106 -2.93774783 -1.37239698\n",
      "  -3.89378778 -0.14469916 -3.15931735 -1.06296823 -4.20025543 -2.32963762\n",
      "  -4.91146984 -1.72344201 -1.00370444 -3.05208872  0.04488392 -4.52201318\n",
      "   0.73442866 -4.25490311 -2.11759897 -2.79912102 -1.77858109  1.10711809\n",
      "   1.69218023 -0.16261172 -1.24841217 -2.99169004 -3.73934851  0.70995074\n",
      "  -1.21407606 -2.95689226 -1.97249113 -6.59205609 -5.9156036   2.39015888\n",
      "  -4.95681435 -1.81607946 -0.72596323 -2.35612119 -4.34206632 -4.17347736\n",
      "  -2.72390861 -0.21580655]\n",
      " [-6.20873921 -4.0920154  -2.69048505 -0.58978787 -5.55087557 -0.01130384\n",
      "  -2.45260506 -4.82702055 -1.2168252  -1.73443987 -3.14421634 -1.73509274\n",
      "  -5.10688484 -0.2710117  -2.52793087 -0.96254727 -4.3982273  -1.73129986\n",
      "  -4.37066511 -1.97300285 -0.86082486 -3.84700108 -0.79679392 -4.2080582\n",
      "   0.16111607 -4.59903474 -1.93864677 -2.58856818 -1.72720695  0.79908065\n",
      "   1.98671382  0.93188729 -0.47768966 -0.73929567 -3.66887977  1.54900007\n",
      "  -1.35794234 -2.78235645 -2.14775007 -7.93442935 -5.61961946  1.51309039\n",
      "  -4.52857728 -2.24145777 -0.68920269 -2.37515396 -4.99289458 -3.8426221\n",
      "  -2.86216298 -1.14742532]\n",
      " [-6.19067302 -3.34339603 -3.26016529 -0.62175041 -4.55923978  0.30007241\n",
      "  -2.43153849 -5.06700325 -0.85358267 -2.93521386 -3.20609634 -1.69873187\n",
      "  -4.2074074  -0.27095363 -2.78869851 -0.96111582 -4.21046307 -1.85213945\n",
      "  -4.86684333 -1.81281508 -1.30804384 -3.12738486 -0.36746994 -4.3167448\n",
      "   0.3148479  -4.2767429  -2.22883696 -2.73706118 -1.80107353  0.8081338\n",
      "   1.88173959  0.51464653 -0.86200074 -2.01167321 -3.60645293  1.15799687\n",
      "  -1.38716149 -2.76449377 -1.96869588 -7.9196474  -5.71988948  1.48734321\n",
      "  -4.63503156 -2.18396984 -0.74447687 -2.17532863 -4.79607326 -3.84010793\n",
      "  -2.81319842 -1.06663612]]\u001b[0m\n",
      "\u001b[32m2024-01-24 08:26:57.173\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mshap.explainers._partition\u001b[0m:\u001b[36mowen\u001b[0m:\u001b[36m308\u001b[0m - \u001b[34m\u001b[1mShould be adding new nodes, 0 of 5\u001b[0m\n",
      "\u001b[32m2024-01-24 08:26:57.174\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mshap.explainers._partition\u001b[0m:\u001b[36mowen\u001b[0m:\u001b[36m308\u001b[0m - \u001b[34m\u001b[1mShould be adding new nodes, 1 of 5\u001b[0m\n",
      "\u001b[32m2024-01-24 08:26:57.177\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mshap.explainers._partition\u001b[0m:\u001b[36mowen\u001b[0m:\u001b[36m308\u001b[0m - \u001b[34m\u001b[1mShould be adding new nodes, 2 of 5\u001b[0m\n",
      "\u001b[32m2024-01-24 08:26:57.178\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mshap.explainers._partition\u001b[0m:\u001b[36mowen\u001b[0m:\u001b[36m308\u001b[0m - \u001b[34m\u001b[1mShould be adding new nodes, 3 of 5\u001b[0m\n",
      "\u001b[32m2024-01-24 08:26:57.179\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mshap.explainers._partition\u001b[0m:\u001b[36mowen\u001b[0m:\u001b[36m308\u001b[0m - \u001b[34m\u001b[1mShould be adding new nodes, 4 of 5\u001b[0m\n",
      "\u001b[32m2024-01-24 08:26:57.183\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mshap.utils._masked_model\u001b[0m:\u001b[36m_full_masking_call\u001b[0m:\u001b[36m75\u001b[0m - \u001b[34m\u001b[1mDid a full masking call with a mask.\u001b[0m\n",
      "\u001b[32m2024-01-24 08:26:57.186\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mshap.models._teacher_forcing\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m95\u001b[0m - \u001b[34m\u001b[1mCalled Teacher Forcing Model to compute long odds\u001b[0m\n",
      "\u001b[32m2024-01-24 08:26:58.451\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mshap.models._teacher_forcing\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m126\u001b[0m - \u001b[34m\u001b[1mCalculated log odds: [[-2.24332890e+00 -5.08903368e+00 -3.06321195e+00 -3.10879591e-01\n",
      "  -4.59254421e+00  3.51871669e-01 -1.73387224e+00 -4.54203425e+00\n",
      "  -1.05809154e+00 -1.11608251e+00 -2.96023070e+00 -1.28672703e+00\n",
      "  -3.83453853e+00 -1.97073123e-02 -2.89918784e+00 -1.06991314e+00\n",
      "  -4.67922950e+00 -2.05949561e+00 -4.65248382e+00 -1.94721843e+00\n",
      "  -7.35209410e-01 -3.57393707e+00 -2.43069719e-01 -4.39730937e+00\n",
      "   5.17677562e-01 -4.54212303e+00 -2.45320561e+00 -2.47038775e+00\n",
      "  -1.79846144e+00  9.82399372e-01  1.84231747e+00  4.50942980e-01\n",
      "  -9.34271045e-01 -1.53800723e+00 -3.55752702e+00  9.75845734e-01\n",
      "  -1.16180731e+00 -2.99384168e+00 -2.00958033e+00 -5.57558805e+00\n",
      "  -5.58858261e+00  2.55101885e+00 -4.91344207e+00 -1.63261595e+00\n",
      "  -8.15051867e-01 -2.54873636e+00 -4.33438941e+00 -3.98692705e+00\n",
      "  -2.61078449e+00 -5.62967028e-01]\n",
      " [-1.75121504e+00 -2.97386426e+00 -2.99512750e+00 -2.58705910e-01\n",
      "  -4.42533114e+00  1.64548878e-01 -1.90954789e+00 -4.95273479e+00\n",
      "  -1.29583531e+00 -1.20426981e+00 -2.93081450e+00 -1.24073567e+00\n",
      "  -4.00218686e+00  3.29827066e-02 -3.26832155e+00 -1.05031084e+00\n",
      "  -4.34071444e+00 -2.19221347e+00 -4.58770376e+00 -1.84923495e+00\n",
      "  -8.08470755e-01 -3.42356586e+00 -8.00291738e-02 -4.47649242e+00\n",
      "   5.15967208e-01 -4.67297904e+00 -1.97832191e+00 -2.64114244e+00\n",
      "  -1.73281023e+00  1.09930718e+00  1.80179371e+00  2.97658403e-01\n",
      "  -9.81431966e-01 -1.54783684e+00 -3.60676109e+00  1.02471235e+00\n",
      "  -1.18016309e+00 -2.96134977e+00 -2.03496955e+00 -7.68862281e+00\n",
      "  -4.65374750e+00  2.81740697e+00 -4.74586581e+00 -1.77023891e+00\n",
      "  -6.64945979e-01 -2.59267016e+00 -4.34078801e+00 -3.89862810e+00\n",
      "  -2.80182807e+00 -3.73791248e-01]\n",
      " [-6.54413678e+00 -3.56471072e+00 -3.16956820e+00 -1.33944385e+00\n",
      "  -5.85799517e+00  8.67363950e-02 -2.38362696e+00 -4.25512262e+00\n",
      "  -5.30726958e-01 -2.26691268e+00 -3.36053536e+00 -1.88156762e+00\n",
      "  -4.35155886e+00 -3.18226773e-01 -2.77887171e+00 -9.14429495e-01\n",
      "  -4.72359126e+00 -1.60114739e+00 -4.63226334e+00 -1.91848401e+00\n",
      "  -1.11367548e+00 -3.46131879e+00 -7.87878405e-01 -4.25419711e+00\n",
      "   2.42878162e-01 -4.44521404e+00 -2.21600302e+00 -2.51036698e+00\n",
      "  -1.74964674e+00  7.85831652e-01  2.01469261e+00  8.51531583e-01\n",
      "  -6.34199332e-01 -1.25151965e+00 -3.62327687e+00  1.41466301e+00\n",
      "  -1.46266936e+00 -2.74470638e+00 -1.99972213e+00 -6.56722166e+00\n",
      "  -6.06704411e+00  1.22720543e+00 -4.81574116e+00 -2.02570388e+00\n",
      "  -8.26644844e-01 -2.10401203e+00 -4.71735823e+00 -3.87572323e+00\n",
      "  -2.66219543e+00 -1.13920088e+00]\n",
      " [-5.64449698e+00 -3.53439099e+00 -2.65792380e+00 -7.32604843e-01\n",
      "  -6.21927969e+00  2.14859721e-01 -2.51306346e+00 -4.76116211e+00\n",
      "  -6.58418155e-01 -2.59952571e+00 -3.32097177e+00 -1.75793437e+00\n",
      "  -4.71745527e+00 -2.05570114e-01 -2.59637089e+00 -8.38669031e-01\n",
      "  -4.25895879e+00 -1.92290682e+00 -4.63807465e+00 -1.82128954e+00\n",
      "  -1.17915591e+00 -3.37899683e+00 -8.00494771e-01 -4.26063859e+00\n",
      "   6.42973478e-02 -4.65837780e+00 -1.89185304e+00 -2.54034532e+00\n",
      "  -1.65507081e+00  8.40589952e-01  1.94945986e+00  8.59314750e-01\n",
      "  -6.86623908e-01 -1.35931528e+00 -3.68393414e+00  1.35443005e+00\n",
      "  -1.44123407e+00 -2.69980969e+00 -2.07689679e+00 -8.01893452e+00\n",
      "  -5.69805572e+00  1.52499355e+00 -4.61531524e+00 -2.23403446e+00\n",
      "  -7.10293166e-01 -2.23057383e+00 -4.86734874e+00 -3.87335363e+00\n",
      "  -2.87050448e+00 -1.24854373e+00]\n",
      " [-1.53377284e+00 -1.71075052e+00 -2.64698662e+00 -1.08185077e-01\n",
      "  -4.65376974e+00  4.32024399e-01 -1.76746960e+00 -4.78885284e+00\n",
      "  -1.12070854e+00 -1.17589695e+00 -2.87748132e+00 -1.34243058e+00\n",
      "  -4.20871569e+00  1.98423217e-01 -2.96268810e+00 -1.10392042e+00\n",
      "  -4.85369495e+00 -1.97694754e+00 -4.63318667e+00 -1.92829752e+00\n",
      "  -8.64569822e-01 -3.87349433e+00 -5.97139858e-01 -4.35762199e+00\n",
      "   5.43333482e-01 -4.78764098e+00 -1.80582655e+00 -2.54798984e+00\n",
      "  -1.74652320e+00  9.31852663e-01  1.89163447e+00  7.61401398e-01\n",
      "  -6.67619242e-01 -1.06862944e+00 -3.65267708e+00  1.25716834e+00\n",
      "  -1.25224112e+00 -2.91995361e+00 -2.06630735e+00 -5.43107516e+00\n",
      "  -5.60583751e+00  2.90359260e+00 -4.79820492e+00 -1.80660230e+00\n",
      "  -7.95092686e-01 -2.46806995e+00 -4.36461223e+00 -4.05150116e+00\n",
      "  -2.60747050e+00 -7.08152777e-01]\n",
      " [-2.62388204e+00 -2.75954753e+00 -3.11248488e+00 -2.96015002e-01\n",
      "  -4.93249045e+00  4.02152073e-01 -1.92290092e+00 -5.30052175e+00\n",
      "  -1.27110159e+00 -1.53643204e+00 -3.03324748e+00 -1.24676917e+00\n",
      "  -3.84186987e+00  1.65350424e-01 -3.30162658e+00 -1.00420957e+00\n",
      "  -4.70994321e+00 -2.18115280e+00 -4.65031491e+00 -1.97122615e+00\n",
      "  -8.96663524e-01 -3.48713460e+00 -8.02754727e-02 -4.33698515e+00\n",
      "   5.27940228e-01 -4.65982440e+00 -1.87772284e+00 -2.66876108e+00\n",
      "  -1.79339167e+00  9.50022430e-01  1.83721485e+00  4.72129366e-01\n",
      "  -8.73491038e-01 -1.60644569e+00 -3.55291694e+00  9.63386968e-01\n",
      "  -1.19494746e+00 -3.00858643e+00 -1.96488053e+00 -5.59656688e+00\n",
      "  -6.31210140e+00  2.53207237e+00 -4.78796268e+00 -1.61279668e+00\n",
      "  -7.23958068e-01 -2.74874760e+00 -4.31193367e+00 -4.03722234e+00\n",
      "  -2.53336018e+00 -5.85745292e-01]\n",
      " [-2.54825181e+00 -5.06295722e+00 -2.85796241e+00 -4.74565403e-01\n",
      "  -5.66483367e+00 -1.33251749e-01 -1.97797956e+00 -4.57473451e+00\n",
      "  -7.24040330e-01 -1.61197400e+00 -3.24602290e+00 -1.62029982e+00\n",
      "  -4.53683318e+00 -5.04833533e-01 -2.92150729e+00 -1.15514386e+00\n",
      "  -4.73886102e+00 -1.59490137e+00 -4.79232942e+00 -1.70562593e+00\n",
      "  -9.42626603e-01 -3.24996123e+00 -7.22981773e-01 -4.41915839e+00\n",
      "   1.24052665e-01 -4.65475920e+00 -1.92297128e+00 -2.53210183e+00\n",
      "  -1.72965072e+00  8.30797365e-01  1.98327383e+00  6.14799055e-01\n",
      "  -8.58630017e-01 -1.60454184e+00 -3.54916803e+00  1.26671140e+00\n",
      "  -1.41205327e+00 -2.79578578e+00 -1.99889807e+00 -7.79789679e+00\n",
      "  -4.92683621e+00  3.00696700e+00 -4.88875813e+00 -1.96800311e+00\n",
      "  -6.54369389e-01 -2.22449538e+00 -4.48926706e+00 -3.98020172e+00\n",
      "  -2.81194057e+00 -7.36871665e-01]\n",
      " [-2.44480516e+00 -3.32290730e+00 -3.15223228e+00 -5.93281142e-01\n",
      "  -5.61994086e+00  2.37181650e-01 -2.04600239e+00 -5.18555829e+00\n",
      "  -5.24047034e-01 -2.22875222e+00 -3.34817219e+00 -1.40640667e+00\n",
      "  -3.79306157e+00 -6.60047642e-02 -3.14919615e+00 -9.64245199e-01\n",
      "  -4.07390267e+00 -2.20411026e+00 -4.94037734e+00 -1.74463102e+00\n",
      "  -1.00014275e+00 -2.89033608e+00  4.85639928e-02 -4.39355708e+00\n",
      "   4.26549783e-01 -4.61270954e+00 -2.05680258e+00 -2.93745333e+00\n",
      "  -1.80881893e+00  9.63389756e-01  1.79296090e+00  8.61917424e-02\n",
      "  -1.07626321e+00 -2.54909696e+00 -3.56331415e+00  8.95490792e-01\n",
      "  -1.35214802e+00 -2.87989886e+00 -1.95669525e+00 -7.77824584e+00\n",
      "  -5.02203919e+00  2.71074613e+00 -4.86190059e+00 -1.85584578e+00\n",
      "  -5.46807451e-01 -2.39058257e+00 -4.38517964e+00 -4.04896106e+00\n",
      "  -2.77797007e+00 -4.79752276e-01]\n",
      " [-2.16620663e+00 -4.46892353e+00 -3.15936768e+00 -8.32775765e-01\n",
      "  -4.78360102e+00  6.98917333e-03 -1.95734736e+00 -3.90398863e+00\n",
      "  -8.59024860e-01 -1.55992441e+00 -3.35021225e+00 -1.56031741e+00\n",
      "  -4.27577433e+00 -4.66714932e-01 -3.10352016e+00 -1.20297343e+00\n",
      "  -4.40228158e+00 -1.86715512e+00 -4.56098889e+00 -1.78906533e+00\n",
      "  -8.77903041e-01 -3.25277233e+00 -2.94012800e-01 -4.45648781e+00\n",
      "   3.90250978e-01 -4.34887406e+00 -2.25298406e+00 -2.43945382e+00\n",
      "  -1.76132612e+00  8.65905837e-01  1.86382760e+00  3.30535118e-01\n",
      "  -1.11467005e+00 -1.79480722e+00 -3.55510199e+00  8.81509738e-01\n",
      "  -1.33589358e+00 -2.94139528e+00 -1.97388425e+00 -6.73508525e+00\n",
      "  -4.65120945e+00  2.52474574e+00 -5.06311223e+00 -1.71139127e+00\n",
      "  -7.58313763e-01 -2.44990803e+00 -4.30572877e+00 -4.10485587e+00\n",
      "  -2.67227079e+00 -5.04288941e-01]\n",
      " [-1.78555656e+00 -4.08158332e+00 -2.83722168e+00 -9.20003805e-01\n",
      "  -4.67176539e+00  1.49249111e-01 -1.84012079e+00 -4.22691042e+00\n",
      "  -4.41473206e-01 -1.41008356e+00 -3.03843993e+00 -1.33315125e+00\n",
      "  -4.04770613e+00 -2.12940862e-01 -3.05378663e+00 -1.05044903e+00\n",
      "  -4.02602071e+00 -2.30811610e+00 -4.78007644e+00 -1.61431075e+00\n",
      "  -8.06350911e-01 -3.23517987e+00 -3.29444737e-02 -4.52929910e+00\n",
      "   5.56519092e-01 -4.50022991e+00 -1.94526132e+00 -2.84408235e+00\n",
      "  -1.69150349e+00  1.10191724e+00  1.74927230e+00 -2.29090323e-02\n",
      "  -1.18455080e+00 -2.57636767e+00 -3.74333189e+00  8.53408825e-01\n",
      "  -1.27249083e+00 -2.90716168e+00 -2.01868093e+00 -7.81215808e+00\n",
      "  -4.84412533e+00  2.81233588e+00 -4.83878191e+00 -1.83488857e+00\n",
      "  -5.68671984e-01 -2.42482620e+00 -4.37224296e+00 -4.05901031e+00\n",
      "  -2.86919480e+00 -2.98445016e-01]]\u001b[0m\n",
      "\u001b[32m2024-01-24 08:26:58.453\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mshap.explainers._partition\u001b[0m:\u001b[36mowen\u001b[0m:\u001b[36m308\u001b[0m - \u001b[34m\u001b[1mShould be adding new nodes, 0 of 5\u001b[0m\n",
      "\u001b[32m2024-01-24 08:26:58.454\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mshap.explainers._partition\u001b[0m:\u001b[36mowen\u001b[0m:\u001b[36m308\u001b[0m - \u001b[34m\u001b[1mShould be adding new nodes, 1 of 5\u001b[0m\n",
      "\u001b[32m2024-01-24 08:26:58.456\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mshap.explainers._partition\u001b[0m:\u001b[36mowen\u001b[0m:\u001b[36m308\u001b[0m - \u001b[34m\u001b[1mShould be adding new nodes, 2 of 5\u001b[0m\n",
      "\u001b[32m2024-01-24 08:26:58.458\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mshap.explainers._partition\u001b[0m:\u001b[36mowen\u001b[0m:\u001b[36m308\u001b[0m - \u001b[34m\u001b[1mShould be adding new nodes, 3 of 5\u001b[0m\n",
      "\u001b[32m2024-01-24 08:26:58.459\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mshap.explainers._partition\u001b[0m:\u001b[36mowen\u001b[0m:\u001b[36m308\u001b[0m - \u001b[34m\u001b[1mShould be adding new nodes, 4 of 5\u001b[0m\n",
      "\u001b[32m2024-01-24 08:26:58.463\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mshap.utils._masked_model\u001b[0m:\u001b[36m_full_masking_call\u001b[0m:\u001b[36m75\u001b[0m - \u001b[34m\u001b[1mDid a full masking call with a mask.\u001b[0m\n",
      "\u001b[32m2024-01-24 08:26:58.465\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mshap.models._teacher_forcing\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m95\u001b[0m - \u001b[34m\u001b[1mCalled Teacher Forcing Model to compute long odds\u001b[0m\n",
      "\u001b[32m2024-01-24 08:26:58.968\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mshap.models._teacher_forcing\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m126\u001b[0m - \u001b[34m\u001b[1mCalculated log odds: [[-2.10654081e+00 -4.56939520e+00 -3.12072640e+00 -2.52274213e-01\n",
      "  -4.81692721e+00  1.36351785e-02 -1.87455333e+00 -4.54944455e+00\n",
      "  -1.10246388e+00 -1.21280338e+00 -3.02394103e+00 -1.40952162e+00\n",
      "  -4.17641550e+00 -3.01689124e-01 -3.17441225e+00 -1.27813874e+00\n",
      "  -4.27927847e+00 -1.94427116e+00 -4.37502419e+00 -1.80964610e+00\n",
      "  -7.10968918e-01 -3.47260959e+00 -3.05513346e-01 -4.46313220e+00\n",
      "   3.59979270e-01 -4.58276417e+00 -2.12503897e+00 -2.47470991e+00\n",
      "  -1.69288593e+00  8.41418608e-01  1.89809909e+00  5.43030041e-01\n",
      "  -9.07407724e-01 -1.29939793e+00 -3.46720540e+00  1.08291743e+00\n",
      "  -1.24271954e+00 -2.99902853e+00 -2.12362171e+00 -7.71478534e+00\n",
      "  -4.74439522e+00  2.89573437e+00 -4.84384161e+00 -1.68430126e+00\n",
      "  -6.24889077e-01 -2.59602044e+00 -4.39933255e+00 -3.93618411e+00\n",
      "  -2.87335941e+00 -1.85429843e-01]\n",
      " [-2.85592734e+00 -4.89368234e+00 -3.42993715e+00 -5.01227608e-01\n",
      "  -4.00299142e+00  1.03988485e-01 -1.95802332e+00 -4.64568004e+00\n",
      "  -1.10325073e+00 -1.85693120e+00 -3.12239129e+00 -1.48023141e+00\n",
      "  -4.29524564e+00 -4.43187280e-01 -3.35872176e+00 -1.18172012e+00\n",
      "  -4.30253109e+00 -2.04681921e+00 -4.72867366e+00 -1.77607035e+00\n",
      "  -1.04150274e+00 -3.00595901e+00 -4.67532756e-03 -4.51823102e+00\n",
      "   5.25355879e-01 -4.23111153e+00 -2.21893774e+00 -2.67113331e+00\n",
      "  -1.83948113e+00  9.07459159e-01  1.70533302e+00  4.98951278e-02\n",
      "  -1.30122914e+00 -2.64748571e+00 -3.58147933e+00  6.84183221e-01\n",
      "  -1.23172979e+00 -2.93615480e+00 -1.92817412e+00 -7.85557385e+00\n",
      "  -4.98319013e+00  2.68663184e+00 -4.93159128e+00 -1.81472832e+00\n",
      "  -6.45178051e-01 -2.38923505e+00 -4.30300410e+00 -3.95953434e+00\n",
      "  -2.79317054e+00 -3.77351719e-01]\n",
      " [-8.00512764e+00 -2.13745269e+00 -2.67364246e+00 -1.67220683e-01\n",
      "  -4.69347088e+00  5.01914721e-01 -1.88500441e+00 -4.77475451e+00\n",
      "  -9.33118971e-01 -1.11159379e+00 -2.97334728e+00 -1.42251272e+00\n",
      "  -4.27799440e+00  4.14447435e-02 -2.55577361e+00 -9.93599793e-01\n",
      "  -4.60567827e+00 -1.82692485e+00 -4.31428022e+00 -1.86544484e+00\n",
      "  -8.06987427e-01 -4.11976576e+00 -5.35488174e-01 -4.32362242e+00\n",
      "   5.58823217e-01 -4.65334664e+00 -1.88436459e+00 -2.56797695e+00\n",
      "  -1.75781529e+00  9.25882138e-01  1.96380004e+00  8.56663547e-01\n",
      "  -5.96393176e-01 -1.15141278e+00 -3.56833705e+00  1.32353832e+00\n",
      "  -1.25213486e+00 -2.86616778e+00 -2.05343287e+00 -5.63487473e+00\n",
      "  -6.17055013e+00  1.00646460e+00 -4.65223580e+00 -1.94129397e+00\n",
      "  -8.59850751e-01 -2.52797559e+00 -4.66145096e+00 -3.94207411e+00\n",
      "  -2.64679850e+00 -9.38250652e-01]\n",
      " [-6.97884171e+00 -2.47823855e+00 -3.03618061e+00 -6.71137391e-02\n",
      "  -4.82412092e+00  3.63673554e-01 -2.06526288e+00 -4.92501007e+00\n",
      "  -1.16538511e+00 -1.55843121e+00 -3.09464796e+00 -1.36432376e+00\n",
      "  -3.72750804e+00  9.96216290e-02 -2.83835828e+00 -9.54550211e-01\n",
      "  -4.42799360e+00 -2.02339951e+00 -4.50381541e+00 -1.83877645e+00\n",
      "  -9.09036733e-01 -3.56452055e+00 -7.84762363e-02 -4.29219046e+00\n",
      "   6.15971785e-01 -4.48877988e+00 -2.01514109e+00 -2.47468760e+00\n",
      "  -1.74490951e+00  9.80571576e-01  1.96389739e+00  5.57005882e-01\n",
      "  -7.75646453e-01 -1.64097103e+00 -3.52346977e+00  1.08659440e+00\n",
      "  -1.15237073e+00 -2.94541275e+00 -1.90547194e+00 -5.81022119e+00\n",
      "  -6.47417493e+00  1.20899425e+00 -4.69736979e+00 -1.79499677e+00\n",
      "  -8.89365339e-01 -2.66392311e+00 -4.54415419e+00 -3.98822278e+00\n",
      "  -2.60621955e+00 -6.87147393e-01]]\u001b[0m\n",
      "\u001b[32m2024-01-24 08:26:58.971\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mshap.explainers._partition\u001b[0m:\u001b[36mowen\u001b[0m:\u001b[36m308\u001b[0m - \u001b[34m\u001b[1mShould be adding new nodes, 0 of 2\u001b[0m\n",
      "\u001b[32m2024-01-24 08:26:58.972\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mshap.explainers._partition\u001b[0m:\u001b[36mowen\u001b[0m:\u001b[36m308\u001b[0m - \u001b[34m\u001b[1mShould be adding new nodes, 1 of 2\u001b[0m\n",
      "\u001b[32m2024-01-24 08:26:58.974\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mshap.explainers._partition\u001b[0m:\u001b[36mowen\u001b[0m:\u001b[36m342\u001b[0m - \u001b[34m\u001b[1mStopped with 34 evals because queue is empty (<queue.PriorityQueue object at 0x7d66cb16a140>)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# running tests\n",
    "basic_gpt_test = gpt_basic_shap(basic_test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LqNTHNDHLBGc",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 216,
     "output_embedded_package_id": "1nVNNRDIfGE7NcUHt2lgbD1nMlVg2rt_u"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1706084821265,
     "user_tz": -60,
     "elapsed": 1144,
     "user": {
      "displayName": "Lennard Zündorf",
      "userId": "01714560816823084743"
     }
    },
    "outputId": "7ff3e813-5a32-49fd-e9a4-2fbc7334cd6d"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Output hidden; open in https://colab.research.google.com to view."
     },
     "metadata": {}
    }
   ],
   "source": [
    "# plotting the values\n",
    "from shap import plots\n",
    "\n",
    "plots.text(basic_gpt_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZdIedmj-PQgE"
   },
   "source": [
    "## Testing Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qBsHMam8RecG"
   },
   "source": [
    "### Helper & SHAP Runner Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y4DaRvuxRdmQ"
   },
   "outputs": [],
   "source": [
    "# formatting function for format output text and tokens\n",
    "import re\n",
    "\n",
    "# function to format the model reponse nicely\n",
    "\n",
    "\n",
    "def format_output_text(output: list):\n",
    "    # remove special tokens from list\n",
    "    formatted_output = format_tokens(output)\n",
    "\n",
    "    # start string with first list item if it is not empty\n",
    "    if formatted_output[0] != \"\":\n",
    "        output_str = formatted_output[0]\n",
    "    else:\n",
    "        # alternatively start with second list item\n",
    "        output_str = formatted_output[1]\n",
    "\n",
    "    # add all other list items with a space in between\n",
    "    for txt in formatted_output[1:]:\n",
    "        # check if the token is a punctuation mark\n",
    "        if txt in [\".\", \",\", \"!\", \"?\"]:\n",
    "            # add punctuation mark without space\n",
    "            output_str += txt\n",
    "        # add token with space if not empty\n",
    "        elif txt != \"\":\n",
    "            output_str += \" \" + txt\n",
    "\n",
    "    # return the combined string with multiple spaces removed\n",
    "    return re.sub(\" +\", \" \", output_str)\n",
    "\n",
    "\n",
    "# format the tokens by removing special tokens and special characters\n",
    "def format_tokens(tokens: list):\n",
    "    # define special tokens to remove and initialize empty list\n",
    "    special_tokens = [\"[CLS]\", \"[SEP]\", \"[PAD]\", \"[UNK]\", \"[MASK]\", \"▁\", \"Ġ\", \"</w>\"]\n",
    "    updated_tokens = []\n",
    "\n",
    "    # loop through tokens\n",
    "    for t in tokens:\n",
    "        # remove special token from start of token if found\n",
    "        if t.startswith(\"▁\"):\n",
    "            t = t.lstrip(\"▁\")\n",
    "\n",
    "        # loop through special tokens and remove them if found\n",
    "        for s in special_tokens:\n",
    "            t = t.replace(s, \"\")\n",
    "\n",
    "        # add token to list\n",
    "        updated_tokens.append(t)\n",
    "\n",
    "    # return the list of tokens\n",
    "    return updated_tokens\n",
    "\n",
    "\n",
    "# function to remove orphan whitespaces in a list of text\n",
    "\n",
    "\n",
    "def remove_orphan_whitespaces(texts: list):\n",
    "    # instantiating a new empty list\n",
    "    cleaned_list = []\n",
    "\n",
    "    # loopin over list\n",
    "    for text in texts:\n",
    "        if text != \" \" and text != \"\":\n",
    "            cleaned_list.append(text)\n",
    "\n",
    "    # additionally rmeoving multiple spaces and return\n",
    "    return cleaned_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N1GoIsdER00g"
   },
   "outputs": [],
   "source": [
    "# shap runner functions (copied from above)\n",
    "# CREDIT: Copied and minimally changed from offical shap documentation\n",
    "# see https://shap.readthedocs.io/en/latest/example_notebooks/text_examples/text_generation/Open%20Ended%20GPT2%20Text%20Generation%20Explanations.html\n",
    "\n",
    "# code to run a auto shap explainer (uses PartitionSHAP)\n",
    "from shap import PartitionExplainer\n",
    "from shap import maskers, Explainer\n",
    "from shap.models import TeacherForcing\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "import time\n",
    "\n",
    "# function that runs a basic shap example\n",
    "\n",
    "\n",
    "def basic_shap(text: list, model, tokenizer):\n",
    "\n",
    "    masker = maskers.Text(tokenizer)\n",
    "    masker.mask_token = \" \"\n",
    "\n",
    "    # create explainer and run it\n",
    "    basic_explainer = PartitionExplainer(model, masker)\n",
    "\n",
    "    runtime = time.time()\n",
    "    shap_values = basic_explainer(text)\n",
    "    print(time.time() - runtime)\n",
    "\n",
    "    return shap_values\n",
    "\n",
    "\n",
    "# code to run a teacher forcing shap example\n",
    "\n",
    "\n",
    "def tch_shap(text: list[list:str], model, tokenizer):\n",
    "\n",
    "    # wrap gpt model in teacher forcing wrapper\n",
    "    tch_model = TeacherForcing(model, tokenizer)\n",
    "\n",
    "    # setup masker using an empty string instead of \"...\"\n",
    "    masker = maskers.Text(tokenizer, mask_token=\" \", collapse_mask_token=True)\n",
    "\n",
    "    # setup explainer, generate explanation\n",
    "    tch_explainer = PartitionExplainer(tch_model, masker)\n",
    "    shap_values = tch_explainer(text[0], text[1])\n",
    "\n",
    "    return shap_values\n",
    "\n",
    "\n",
    "# visualizing SHAP Text Masking\n",
    "# CREDIT: Copied and minimally changed from Lilo Wagner, \"Shap’s partition explainer for language models\"\n",
    "## see https://towardsdatascience.com/shaps-partition-explainer-for-language-models-ec2e7a6c1b77\n",
    "\n",
    "\n",
    "def viz_masking(text: str, tokenizer):\n",
    "\n",
    "    # creating a new masker\n",
    "    masker = maskers.Text(tokenizer, mask_token=\" \", collapse_mask_token=True)\n",
    "\n",
    "    # clustering text using the master\n",
    "    clust_text_val = masker.clustering(text)\n",
    "    clust_text_splits = masker.feature_names(text)[0]\n",
    "\n",
    "    # creating a plot figure and plotting\n",
    "    fig = plt.figure(figsize=(8, 4))\n",
    "    dn = dendrogram(clust_text_val, labels=clust_text_splits)\n",
    "    plt.xlabel(\"Input Texts\")\n",
    "    plt.ylabel(\"Partition Tree Levels\")\n",
    "    plt.title(\"Visualization of Clustering By SHAP Masker\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ULqWUXMCRazg"
   },
   "source": [
    "### GODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AOFyz6MCRaJ4"
   },
   "outputs": [],
   "source": [
    "# formatting function to formatting input for the model\n",
    "# CREDIT: Adapted from official interference example on Huggingface\n",
    "## see https://huggingface.co/microsoft/GODEL-v1_1-large-seq2seq\n",
    "def gd_format_prompt(message: str, system_prompt: str, knowledge: str = \"\"):\n",
    "\n",
    "    # adds knowledge text if not empty\n",
    "    if knowledge != \"\":\n",
    "        knowledge = \"[KNOWLEDGE] \" + knowledge\n",
    "\n",
    "    # adds the message to the prompt\n",
    "    prompt = f\" {message}\"\n",
    "    # combines the entire prompt\n",
    "    full_prompt = f\"{system_prompt} [CONTEXT] {prompt} {knowledge}\"\n",
    "\n",
    "    # returns the formatted prompt\n",
    "    return full_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YlAHlIV3XcsJ"
   },
   "outputs": [],
   "source": [
    "# running PartitionSHAP Explainer on GODEL\n",
    "# imports\n",
    "from shap import plots\n",
    "\n",
    "# getting formatted prompt\n",
    "gd_test_prompt = gd_format_prompt(\n",
    "    \"Does money buy happiness?\",\n",
    "    \"Given a dialog context, you need to respond empathically.\",\n",
    ")\n",
    "\n",
    "# visualizing clustering done by SHAP masker\n",
    "viz_masking(gd_test_prompt, gd_tokenizer)\n",
    "\n",
    "# running tests\n",
    "basic_gd_test = basic_shap([gd_test_prompt], gd_model, gd_tokenizer)\n",
    "\n",
    "# plotting the values\n",
    "plots.text(basic_gd_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DNyV9QYXcWrv"
   },
   "outputs": [],
   "source": [
    "# running a teacher forced SHAP Explainer on GODEL\n",
    "# imports\n",
    "from shap import plots\n",
    "\n",
    "# text text data\n",
    "gd_tch_test_text = [\n",
    "    [gd_test_prompt, gd_test_prompt, gd_test_prompt, gd_test_prompt, gd_test_prompt],\n",
    "    [\n",
    "        (\n",
    "            \"It's heartening to hear you view money as a means to happiness; do you\"\n",
    "            \" find that this belief positively impacts your life?\"\n",
    "        ),\n",
    "        (\n",
    "            \"Your perspective on money and happiness is intriguing; have you always\"\n",
    "            \" felt this way, or has your opinion evolved over time?\"\n",
    "        ),\n",
    "        (\n",
    "            \"I agree that money can be a tool for happiness; it's great you're thinking\"\n",
    "            \" about this, what's your most fulfilling experience with it?\"\n",
    "        ),\n",
    "        (\n",
    "            \"Your view is quite insightful; do you think there's more to happiness than\"\n",
    "            \" just money and possessions?\"\n",
    "        ),\n",
    "        (\n",
    "            \"That's an optimistic approach to wealth and happiness; what other factors\"\n",
    "            \" do you believe play a role in achieving true contentment?\"\n",
    "        ),\n",
    "    ],\n",
    "]\n",
    "\n",
    "# running test with predfined class\n",
    "tch_gd_test = tch_shap(tch_test_text, gd_model, gd_tokenizer)\n",
    "\n",
    "# plotting the values\n",
    "plots.text(tch_gd_test)\n",
    "plots.bar(tch_gd_test[0, :, \"empathically\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Its9gfqCgsh4"
   },
   "source": [
    "### Mistral AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f0UjNqXIbp0D"
   },
   "outputs": [],
   "source": [
    "# formatting function to format input for the model\n",
    "# CREDIT: Inspired by offical documentation and example on Huggingface\n",
    "## see https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1\n",
    "def mistral_format_prompt(message: str, system_prompt: str):\n",
    "    prompt = (\n",
    "        f\"<s>[INST] {system_prompt} [/INST] Hello, how can I assist you\"\n",
    "        f\" today?</s>[INST] {message} [/INST]\"\n",
    "    )\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GUnl3Gd-zSfH"
   },
   "outputs": [],
   "source": [
    "# basic generation function for the model\n",
    "# CREDIT: Adapted from by offical documentation and example on Huggingface\n",
    "## see https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1\n",
    "def mistral_generate(message: str=\"Does money buy happiness?\", system_prompt: str=\"Given a dialog context, you need to respond empathically.\"):\n",
    "\n",
    "  # getting device again and updating config\n",
    "  device = torch.device(\"gpu\") if torch.cuda.is_available()\n",
    "  mistral_model.to(device)\n",
    "\n",
    "  # formatting prompt\n",
    "  prompt = mistral_format_prompt(message, system_prompt)\n",
    "\n",
    "  # tokenizing inputs\n",
    "  input_ids = mistral_tokenizer.encode(f\"{prompt}\", return_tensors=\"pt\")\n",
    "  model_inputs = input_ids.to(device)\n",
    "\n",
    "  # generating response and decoding it\n",
    "  generated_ids = mistral_model.generate(model_inputs)\n",
    "  decoded = mistral_tokenizer.decode(generated_ids)\n",
    "\n",
    "  # return text\n",
    "  return decoded[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L5GgZv_y0BHg"
   },
   "outputs": [],
   "source": [
    "print(\n",
    "    mistral_generate(\n",
    "        message=\"Does money buy happiness?\",\n",
    "        system_prompt=\"Given a dialog context, you need to respond empathically.\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-t-3XFRAoEpx"
   },
   "outputs": [],
   "source": [
    "# function to test shap TextGeneration, TeacherForing Models\n",
    "# -> Explainer automatically wraps mistral model in these\n",
    "from shap.models import TextGeneration, TeacherForcing\n",
    "\n",
    "# create formatted prompt\n",
    "mistral_text = mistral_format_prompt(\n",
    "    message=\"Does money buy happiness?\",\n",
    "    system_prompt=\"Given a dialog context, you need to respond empathically.\",\n",
    ")\n",
    "\n",
    "# update tokenizer config, create mistral teacher forcing model\n",
    "mistral_tokenizer.pad_token = mistral_tokenizer.eos_token\n",
    "mistral_tch_model = TeacherForcing(mistral_model, mistral_tokenizer)\n",
    "\n",
    "# logits = mistral_tch_model.get_teacher_forced_logits(np.array([mistral_text]),np.array([\"I understand that this is a common question with no definitive answer, as everyone's experiences and priorities are unique.\"]))\n",
    "tch_output = mistral_tch_model(\n",
    "    np.array([mistral_text, mistral_text, mistral_text]),\n",
    "    np.array([\n",
    "        \"I understand that this is a common question with no definitive answer, as\"\n",
    "        \" everyone's experiences and priorities are unique.\"\n",
    "    ]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZOQryM_boB8A"
   },
   "outputs": [],
   "source": [
    "from shap import plots\n",
    "\n",
    "# running basic shap with mistral\n",
    "basic_mist_test = basic_shap([mistral_text], mistral_model, mistral_tokenizer)\n",
    "\n",
    "# plotting the values\n",
    "plots.text(basic_mist_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ztQzjq7MgcGe"
   },
   "source": [
    "### Comment\n",
    "\n",
    "It is evident that the calculation of SHAP values does not work correctly with the Mistral Model. This is because the teacher forced logits are not calculated correctly for the different nodes.\n",
    "\n",
    "Even through several debugging and fixing steps it was not possible to resolve the issue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EGq8hSzUW4Nu"
   },
   "source": [
    "### LlaMa 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "894xmol-W8yl"
   },
   "outputs": [],
   "source": [
    "# formatting function to format input for the model\n",
    "# CREDIT: Adapted from Philipp Schmid\n",
    "## see https://www.philschmid.de/llama-2#how-to-prompt-llama-2-chat\n",
    "def llama_format_prompt(message: str, system_prompt: str):\n",
    "    prompt = f\"<s>[INST] <<SYS>>\\n{system_prompt}\\n<</SYS>>\\n\\n{message} [/INST]\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W396FKyoW9iZ"
   },
   "outputs": [],
   "source": [
    "from shap import plots\n",
    "\n",
    "# create formatted prompt\n",
    "llama_text = llama_format_prompt(\n",
    "    message=\"Does money buy happiness?\",\n",
    "    system_prompt=\"Given a dialog context, you need to respond empathically.\",\n",
    ")\n",
    "\n",
    "# running basic shap with mistral\n",
    "basic_llama_test = basic_shap([llama_text], llama_model, llama_tokenizer)\n",
    "\n",
    "# plotting the values\n",
    "plots.text(basic_llama_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sY2kIkiogx-I"
   },
   "source": [
    "### Comment\n",
    "\n",
    "It is evident that the calculation of SHAP values does not work correctly with the Mistral Model. This is because the teacher forced logits are not calculated correctly for the different nodes.\n",
    "\n",
    "Even through several debugging and fixing steps it was not possible to resolve the issue."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "Pi0_8gFxgVjx",
    "TgnG_w5xCuHa",
    "qBsHMam8RecG"
   ],
   "machine_shape": "hm",
   "provenance": [
    {
     "file_id": "https://github.com/LennardZuendorf/thesis-files/blob/master/SHAP_TextGeneration.ipynb",
     "timestamp": 1702207681762
    }
   ],
   "authorship_tag": "ABX9TyOJdE0IvSJpeMFM9qlqNWxx"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}